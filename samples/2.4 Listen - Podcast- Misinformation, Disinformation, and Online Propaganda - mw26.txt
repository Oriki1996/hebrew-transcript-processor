[דובר 2] (0:00 - 0:26)
Welcome back for another Deep Dive. Today, we're going to be tackling a topic that feels very ripped from the headlines. Misinformation, disinformation and online propaganda.

We're going to be looking at this topic through a chapter from the book, Misinformation, Disinformation and Online Propaganda by Andrew M. Gess and Benjamin A. Lyons.

And I think our mission today is to unpack these terms, their impact, and maybe some surprising insights about how they actually operate online.

[דובר 1] (0:26 - 0:33)
Yeah, it's a topic that's more relevant now than ever, particularly as the lines between these terms continue to blur in the digital age.

[דובר 2] (0:33 - 0:51)
For sure. So let's jump right into it. Imagine you're scrolling online and you see a fact that just feels kind of off.

And that's misinformation in action. It's warping our understanding of the truth, but without any sort of like intention behind it necessarily. But how is that different from disinformation or propaganda?

[דובר 1] (0:51 - 1:13)
So you can think of disinformation as misinformation, but it has a specific purpose behind it. It's a deliberate attempt to deceive and manipulate. And a lot of times this is for political or economic gain.

And then with propaganda, while it can use truthful information, it's all about pushing a specific agenda, often by disparaging opposing viewpoints.

[דובר 2] (1:13 - 1:20)
You know, it's interesting that Gess and Lyons point out that misinformation is actually different from like rumors or conspiracy theories.

[דובר 1] (1:20 - 1:20)
Yeah.

[דובר 2] (1:21 - 1:24)
Because, you know, those may or may not be true. But misinformation is definitely false.

[דובר 1] (1:24 - 1:31)
It's a really crucial distinction, and it helps us understand the motivations and strategies behind those spreading misinformation.

[דובר 2] (1:32 - 1:40)
Now that we've kind of got a handle on the definitions, let's actually dive into the people behind the misinformation. You might be surprised by who is actually pulling the strings here.

[דובר 1] (1:40 - 1:45)
The first example that comes to mind is the case of the Macedonian teenagers during the 2016 U.S. election.

[דובר 2] (1:45 - 1:47)
Wait, teenagers? Really?

[דובר 1] (1:47 - 2:04)
Yeah. It sounds unbelievable, but over a hundred pro-Trump fake news websites were operating out of Vilas, Macedonia. And it was teenagers running these websites and their motivation.

It really wasn't political ideology, but it was profit. They were drawn to the ad revenue generated by clicks and engagement.

[דובר 2] (2:05 - 2:07)
So less about politics, more about economics.

[דובר 1] (2:07 - 2:20)
Exactly. Research suggests that they leaned heavily pro-Trump just because those stories got more engagement. And there's even some evidence to suggest that there were potential connections to American and British political consultants.

[דובר 2] (2:20 - 2:26)
Oh, wow. So that adds a whole other layer to this story. It's like a real life thriller unfolding online.

[דובר 1] (2:26 - 2:30)
Yeah. Speaking of thrillers, we can't forget about the Russian troll factory.

[דובר 2] (2:30 - 2:30)
Yeah.

[דובר 1] (2:30 - 2:33)
The Internet Research Agency or the IRA.

[דובר 2] (2:33 - 2:36)
Those guys sound a little closer to those shadowy figures I imagined.

[דובר 1] (2:36 - 2:47)
Right. Their approach was much more systematic. They operated like a content farm, churning out propaganda with workers managing tons of fake accounts, all in the effort to influence public opinion.

[דובר 2] (2:48 - 2:49)
That sounds so organized.

[דובר 1] (2:49 - 3:05)
Yeah, it was very organized. And research based on Twitter data confirms what journalists have been reporting. These IRA accounts pushed junk news.

They impersonated American users and they even targeted local news sources to exploit people's trust.

[דובר 2] (3:05 - 3:11)
That's scary. Exploiting local news sources. I mean, it really highlights the lengths they were willing to go to spread their message.

[דובר 1] (3:11 - 3:21)
What about those online communities, though, that are known for spreading conspiracy theories or extremist content? They may not be as organized as like the IRA, but they still play a role.

[דובר 2] (3:21 - 3:26)
Absolutely. Online spaces like 4chan and 8chan have become breeding grounds for these ideologies.

[דובר 1] (3:27 - 3:31)
So we're talking about a much broader landscape than just state sponsored actors.

[דובר 2] (3:31 - 3:41)
Right. So while some individuals in these communities have clear ideological motives, others are just driven by a desire to cause chaos or just for the thrill of it.

[דובר 1] (3:42 - 4:06)
It's like a mix of motivations then. And what's really interesting is that they don't stay confined to these fringe platforms. No, they actively use mainstream social media to spread their content and influence conversations.

Yeah, they're basically hijacking algorithms designed to connect us to spread disinformation. And it brings up an important question. Why is there a demand for this kind of content in the first place?

[דובר 2] (4:06 - 4:10)
That's what I always wonder about. It's like if we didn't buy it, they wouldn't be selling it right.

[דובר 1] (4:10 - 4:30)
Right. You've hit a crucial point. There's a complex interplay of factors that create this demand for misinformation.

And one thing is we live in this world of information overload and our attention spans are constantly shrinking. And this is where misinformation thrives. It's often attention grabbing, emotionally charged.

[דובר 2] (4:30 - 4:32)
It's like the Internet equivalent of clickbait.

[דובר 1] (4:32 - 4:38)
Exactly. And then social media algorithms that are designed to maximize engagement can inadvertently favor this type of content.

[דובר 2] (4:39 - 4:44)
So it's not just that people are seeking out misinformation. It's also being pushed on them by the platforms they use.

[דובר 1] (4:45 - 4:57)
That's right. But Guest Alliance point out a key insight about the consumption of misinformation. It's incredibly skewed.

It's not everyone falling for this. It's a relatively small number of producers and consumers that are driving a lot of the engagement.

[דובר 2] (4:57 - 5:23)
That's a good point to emphasize. It's easy to feel like everyone is being duped, but the reality is much more nuanced. Right.

It's not about everyone believing this stuff, but a smaller group creating a disproportional impact. So how does this misinformation actually spread? Is it as simple as people sharing things they see?

Or is there more to it? I mean, it can't just be as easy as hitting that share button, can it?

[דובר 1] (5:23 - 5:23)
Right.

[דובר 2] (5:23 - 5:26)
What are the actual mechanisms behind spreading this misinformation?

[דובר 1] (5:27 - 5:40)
Well, there's a lot more at play than just sharing. Remember those social bots that we were talking about earlier, the ones that were amplifying content during the 2016 election? There's still a key player, especially in those early stages when something is first gaining traction.

[דובר 2] (5:40 - 5:41)
It's like a digital hype machine.

[דובר 1] (5:41 - 5:49)
Yeah, exactly. And they often target those accounts with large followings to amplify that message and give it more legitimacy.

[דובר 2] (5:49 - 5:56)
That's kind of unsettling how these bots can really manipulate the conversation online. Are there any other tactics that we should be aware of?

[דובר 1] (5:56 - 6:03)
Have you ever come across those breaking news accounts on Twitter? The ones that try to mimic legitimate news sources?

[דובר 2] (6:03 - 6:09)
Yeah, totally. They always have those super dramatic headlines and usernames that look like real news organizations.

[דובר 1] (6:09 - 6:14)
That's exactly their strategy. They exploit our trust in those established media outlets.

[דובר 2] (6:14 - 6:14)
Right.

[דובר 1] (6:14 - 6:22)
They build large followings by posing as authority figures, and then they use that platform to spread misinformation. It's like a wolf in sheep's clothing.

[דובר 2] (6:23 - 6:35)
Yeah. It's a good reminder that you can't really take anything at face value online. But it's not just the tactics of the people spreading this misinformation, right?

Like our own biases can make us more susceptible to falling for it.

[דובר 1] (6:36 - 6:40)
Yeah, you're absolutely right. Our own cognitive biases play a huge role.

[דובר 2] (6:40 - 6:40)
OK.

[דובר 1] (6:40 - 6:54)
For instance, confirmation bias. That's a powerful one. We naturally gravitate towards information that confirms our existing beliefs, right?

Even if it's not true. And then we dismiss information that challenges those beliefs, even if it is well supported by evidence.

[דובר 2] (6:54 - 7:04)
So we are already predisposed to believe something. We're more likely to accept information, even if it's misinformation that supports that belief without really questioning it.

[דובר 1] (7:04 - 7:18)
Exactly. And then there's the impact of social biases like homophily, the tendency to connect with like minded people. And this creates these echo chambers where misinformation is constantly reinforced and dissenting voices are kind of silenced.

[דובר 2] (7:18 - 7:24)
That's scary. Like, are we becoming trapped in these echo chambers where misinformation just reigns supreme?

[דובר 1] (7:25 - 7:41)
Yeah, that's a that's a good question. And unfortunately, social media algorithms are designed to keep us engaged so they can exacerbate this problem. They prioritize content that we're likely to interact with, which often means it's very emotionally charged content regardless of whether it's true or not.

[דובר 2] (7:41 - 7:42)
So it's like a perfect storm.

[דובר 1] (7:42 - 7:42)
Yeah.

[דובר 2] (7:43 - 7:52)
Our own biases, these algorithms that prioritize engagement over accuracy, and then these manipulative tactics used by those spreading this information.

[דובר 1] (7:52 - 7:52)
Right.

[דובר 2] (7:52 - 7:57)
Because inlines also highlight this whole idea of novelty over falsity.

[דובר 1] (7:57 - 7:57)
Oh, yeah.

[דובר 2] (7:57 - 7:59)
Can you unpack that a little bit? What does that mean?

[דובר 1] (7:59 - 8:18)
Yeah. So studies have shown that people are just more likely to share information that's novel or unique regardless of whether it's true or false. We're drawn to information that will get us noticed or spark a reaction.

It's like a form of social currency. The more outrageous or unusual the information, the more valuable it seems.

[דובר 2] (8:19 - 8:25)
So it's not necessarily about believing it, but sharing something that feels new and exciting and makes you look like you're in the know.

[דובר 1] (8:25 - 8:41)
Exactly. We often share things before verifying them, especially if they align with our existing beliefs or they elicit a strong emotional response. And this makes combating misinformation even more difficult because even those who don't believe the content can still contribute to its spread.

[דובר 2] (8:41 - 9:00)
So we've got these bots, we've got these fake news accounts working to amplify this information. Then you add in our own biases and algorithms that prioritize engagement over accuracy. It creates this environment where misinformation can spread so quickly.

But what does this all really mean? What's the impact beyond people just believing false things?

[דובר 1] (9:00 - 9:22)
That's the important question. And the answer is that the impacts of misinformation go way beyond simply believing falsehoods. It can erode trust in institutions, it can increase cynicism, and it can deepen divides between groups.

It's like this slow poison seeping into the fabric of society and undermining our ability to have conversations and address critical issues.

[דובר 2] (9:23 - 9:27)
So let's break that down a bit. How does misinformation erode trust?

[דובר 1] (9:28 - 9:37)
Well, when we're constantly bombarded with information that challenges those legitimate sources like the government, the media, scientific experts, it's bound to have an impact on our perception.

[דובר 2] (9:38 - 9:45)
So it's this constant trip, trip, trip. Each piece of misinformation may not seem like a big deal, but over time it chips away at our trust.

[דובר 1] (9:45 - 9:58)
Exactly. And that can lead to some serious consequences in the real world. If people lose faith in institutions, they're less likely to engage in the democratic process to follow public health guidelines or even believe vital information that's crucial for their own well-being.

[דובר 2] (9:59 - 10:10)
It's like this downward spiral then. Misinformation leads to distrust, which leads to disengagement, which weakens those institutions further. And then there's that rise of cynicism that goes along with that distrust, too.

[דובר 1] (10:10 - 10:32)
Absolutely. When people are constantly exposed to misinformation, they start to feel like everything is rigged. The truth is elusive and no one can be trusted.

And this leads to feelings of hopelessness, apathy, disenfranchisement, like their voices don't matter. And that can be incredibly damaging to a healthy democracy because people lose faith in the system and disengage from civic participation.

[דובר 2] (10:33 - 10:38)
So it's not just about believing specific lies, but developing this broader sense of disillusionment.

[דובר 1] (10:39 - 10:39)
Right.

[דובר 2] (10:39 - 10:40)
And powerlessness.

[דובר 1] (10:40 - 10:40)
Yeah.

[דובר 2] (10:41 - 10:46)
How does misinformation then contribute to this growing divide between different political groups?

[דובר 1] (10:46 - 11:08)
Well, it feeds into those existing biases and social divisions that we talked about earlier. It spreads biased or misleading information that confirms existing prejudices. And this deepens the gulf between those different political perspectives and makes it harder to find any sort of common ground.

It also fuels effective polarization. That's where people develop increasingly negative feelings toward those who hold different political beliefs.

[דובר 2] (11:09 - 11:15)
So it's not just disagreeing on policies anymore. It's actually feeling this animosity toward people on the other side.

[דובר 1] (11:15 - 11:15)
Right.

[דובר 2] (11:15 - 11:19)
It's like it's pouring gasoline on an already burning fire.

[דובר 1] (11:19 - 11:19)
Exactly.

[דובר 2] (11:20 - 11:24)
Making it harder to have any productive conversations about the issues that really matter.

[דובר 1] (11:25 - 11:28)
You mentioned that misinformation can even set the agenda.

[דובר 2] (11:28 - 11:43)
Yeah, you're right. Even if people don't buy into the misinformation itself, it can still influence which topics are considered important. They can shape public discourse and prioritize certain narratives, even if those narratives are based on distortions or outright falsehoods.

[דובר 1] (11:43 - 11:54)
It's a whole other layer of impact to be aware of. And speaking of impact, Kes and Lenz point out that a lot of research focuses on these like direct persuasive effects of misinformation.

[דובר 2] (11:54 - 11:54)
Right.

[דובר 1] (11:55 - 12:25)
Like whether it changes voting behavior or not. But those effects can be surprisingly hard to measure. That's true.

While we can clearly see misinformation spreading, actually proving its influence on people's actions and beliefs is challenging. The most dangerous effects might be those long term consequences that we've been talking about. The erosion of trust, the rise in cynicism and those deepening political divides.

Those are a lot harder to quantify, but they have the potential to just reshape society in some really profound ways.

[דובר 2] (12:25 - 12:44)
It's like trying to measure the damage from an earthquake. You can see the collapsed buildings, but the real devastation is hidden below the surface. So where do we go from here?

Is there any hope? What can we do to fight back against that? I mean, it feels like we've uncovered this pretty bleak picture.

Yeah. Where do we even begin to address a problem this big?

[דובר 1] (12:44 - 12:57)
It's definitely a challenge, but I do think there is hope. And it starts with empowering ourselves as individuals to be more discerning and resilient when we face misinformation. We have to build up our defenses against these harmful narratives.

[דובר 2] (12:58 - 13:01)
I like that. So how do we actually go about strengthening those defenses?

[דובר 1] (13:01 - 13:15)
Well, it starts with cultivating a healthy skepticism and becoming more critical about the information that we consume. Question everything, especially information that just confirms your biases or triggers a strong emotional reaction.

[דובר 2] (13:15 - 13:21)
So kind of taking a step back and evaluating information before just accepting it as truth.

[דובר 1] (13:21 - 13:21)
Right.

[דובר 2] (13:21 - 13:25)
Especially when it seems too good to be true or makes you really mad.

[דובר 1] (13:25 - 13:32)
Exactly. We have to break free from that impulse to react immediately and really engage in some thoughtful reflection.

[דובר 2] (13:32 - 13:32)
Right.

[דובר 1] (13:32 - 13:41)
You know, ask yourself, is this information coming from a reliable source? Is there evidence to support it? Or am I just reacting emotionally?

[דובר 2] (13:41 - 13:43)
It's like pausing before you hit the share button.

[דובר 1] (13:44 - 13:44)
Yeah.

[דובר 2] (13:44 - 13:47)
And being like, hold on. Do I really want to amplify this?

[דובר 1] (13:47 - 13:54)
Yeah. That's a great way to put it. And if you're unsure about something, fact checking websites like Snopes or PolitiFact can be really valuable resources.

[דובר 2] (13:54 - 13:55)
Yeah, for sure.

[דובר 1] (13:55 - 14:00)
They provide evidence based analysis and help debunk a lot of the false claims that are circulating online.

[דובר 2] (14:00 - 14:07)
Those are definitely my go to's. But like, let's be realistic. Not everyone have the time to fact check every single thing that they see online.

[דובר 1] (14:07 - 14:07)
Right.

[דובר 2] (14:07 - 14:13)
Are there any other practical strategies for kind of navigating this world of misinformation?

[דובר 1] (14:14 - 14:18)
Yeah. One really effective approach is diversifying the sources that you get your information from.

[דובר 2] (14:19 - 14:19)
OK.

[דובר 1] (14:19 - 14:29)
If you're only getting your news from one or two places, you're more likely to just get a narrow perspective. And that can lead to some blind spots and reinforce those existing biases.

[דובר 2] (14:29 - 14:34)
So it's about breaking out of those echo chambers and exposing yourself to different viewpoints.

[דובר 1] (14:34 - 14:36)
Absolutely. Even ones you might not agree with.

[דובר 2] (14:37 - 14:37)
Right.

[דובר 1] (14:37 - 14:46)
It's all about challenging your assumptions and being open to new information. Surround yourself with those diverse perspectives and get a more complete picture of the issues.

[דובר 2] (14:47 - 14:54)
That makes a lot of sense. But what about those friends and family members who seem like they're really caught in the web of misinformation?

[דובר 1] (14:55 - 14:55)
Yeah.

[דובר 2] (14:55 - 14:58)
How do we approach those conversations without things getting out of hand?

[דובר 1] (14:58 - 15:14)
Yeah. That's a tough one. And it takes empathy and critical thinking.

Remember, they may genuinely believe the information that they're sharing, even if it's false. Right. Approach the conversation from a place of understanding rather than trying to prove them wrong.

[דובר 2] (15:14 - 15:16)
So more like building bridges rather than burning them.

[דובר 1] (15:16 - 15:20)
Exactly. Avoid being confrontational or dismissive.

[דובר 2] (15:20 - 15:20)
OK.

[דובר 1] (15:20 - 15:32)
That will just make them defensive and less likely to engage in a real dialogue. Right. Focus on shared values and goals.

Instead of arguing about the facts, try to find common ground and build from there.

[דובר 2] (15:32 - 15:36)
So find that point of connection that can actually start a real conversation.

[דובר 1] (15:36 - 15:39)
Yeah. And sometimes the best thing you can do is just listen.

[דובר 2] (15:39 - 15:40)
That's good.

[דובר 1] (15:40 - 15:44)
People often just need to feel heard and understood, even if you don't agree with them.

[דובר 2] (15:44 - 15:44)
Right.

[דובר 1] (15:45 - 15:49)
Creating that space for open and respectful dialogue is so important.

[דובר 2] (15:49 - 15:53)
It is. And that goes for so many types of conversations, not just the ones about misinformation.

[דובר 1] (15:54 - 15:54)
Yeah.

[דובר 2] (15:54 - 16:00)
But how do we move beyond just our individual efforts? How do we address this as like a society?

[דובר 1] (16:00 - 16:19)
I think one of the most important things we can do is just talk about it more. Right. We have to break the taboos surrounding this issue and normalize critical thinking, fact checking, questioning authority.

The more we talk about the dangers of misinformation, the better equipped we'll be as individuals and as a society to actually combat it.

[דובר 2] (16:19 - 16:22)
It's like shining a light on the problem so we can all see it clearly.

[דובר 1] (16:22 - 16:31)
Exactly. This isn't just about protecting ourselves from misinformation. It's about protecting our democracy and making sure that public discourse is based on facts and reason.

[דובר 2] (16:32 - 16:45)
Right. Because a well-informed public is key for a healthy democracy. Right.

So what is the main takeaway for our listeners today? What can they do to navigate this crazy information landscape?

[דובר 1] (16:46 - 17:08)
I think the takeaway is this. We are not powerless when it comes to misinformation. We have the power to be more discerning about the information we consume, to diversify our sources and engage in thoughtful conversations and to hold those in power accountable for spreading falsehoods.

And by working together, we can reduce the harm of misinformation and protect the integrity of our shared reality.

[דובר 2] (17:09 - 17:29)
That is a really powerful message of hope. Thank you so much for taking us on this deep dive into misinformation, disinformation and online propaganda. It's been a really great conversation.

And to our listeners, remember, knowledge is power and critical thinking is our best weapon in the fight against misinformation. Until next time, stay curious, stay informed and stay vigilant.
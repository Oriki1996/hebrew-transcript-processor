[דובר 6] (0:00 - 0:33)
Which our enemies can make it look like anyone is saying anything at any point in time Even if they would never say those things The speech you're watching never actually happened for instance, they could have me say things like I Don't know President Trump is a total and complete dipshit. It looks and sounds like Barack Obama, but it's a fake You see I would never say these things at least not in a public address, but Someone else would someone like Jordan Peele.

[דובר 1] (0:35 - 1:48)
This is a dangerous time Moving forward we need to be more vigilant with what we trust from the internet Director Jordan Peele made this video to warn people about a new technology Technology that in the wrong hands could be a modern-day weapon of war. Could this be the future of fake news? I'm in Los Angeles the home of movie magic to learn more about the power and the possibility of this new technology It's a place where the impossible can become possible and you never know when you might see a star But I'm not here to meet real celebrities I'm here to meet fake ones Welcome to Pinscreen.

Great. Thank you. Come on in How Lee is the CEO of Pinscreen and the director of the vision and graphics lab at USC?

Pinscreen is using artificial intelligence to create artificial people Primarily avatars for video games and watch how easy it is.

[דובר 2] (1:48 - 2:10)
I'm gonna take a picture Right, so I just took a selfie here and when I press create avatar now, it's Uploading the picture to the server and it's gonna generate a full avatar of myself and You know, I can just record and then send this as a video. Hey mark. How are you?

[דובר 1] (2:13 - 2:17)
Why is it why is it that you want to generate these virtual humans for what for what end?

[דובר 2] (2:18 - 2:33)
Yeah, it has to be An immersive experience where you're in Toronto and I'm in LA and we can have a face-to-face in-person communication inside a virtual world, so it's sort of like building You know a system like the matrix

[דובר 1] (2:34 - 3:01)
The line between real and virtual humans is getting increasingly blurred When actor Paul Walker passed away during the filming of furious 7 how was part of the team that was called in to help complete? The movie they brought the actor back to life with computer-generated graphics But now technology like this is no longer limited to Hollywood studios And how wants to show us the potential dangers of this emerging technology?

[דובר 2] (3:02 - 3:20)
we have passed beyond the stage where these type of Effects are not only possible in visual effects studios where you know It would cost a lot to generate this type of content. You can basically make these type of Technologies accessible to the general audience. So creating awareness is important.

[דובר 1] (3:21 - 3:34)
How difficult is it to Digitize make me sort of a virtual person Yeah, it's getting easier and easier and the best way is just to have a picture of some that's fascinating And you can do that with me.

[דובר 2] (3:34 - 3:42)
We can do it with you right now. All right, let's do it. Let's do it.

Okay. All right, I Sit in here.

[דובר 11] (3:42 - 3:42)
Okay.

[דובר 2] (3:43 - 3:57)
So what do I need to do? So that's a simple webcam and We're we just you know, took a picture of you and that's it Now it already built your avatar it's already built my avatar it has already built It was that easy.

[דובר 1] (3:57 - 4:06)
My photo can be turned into video Watches the computer operator becomes puppet master with my own image That's fascinating.

[דובר 2] (4:06 - 4:12)
The blue part is actually a three-dimensional mesh that is tracking his face It's analyzing his facial expressions.

[דובר 1] (4:13 - 4:31)
So but the emotions as well so I can be happy I can be sad I can be angry. You can you can recreate me to whatever the context it is that you want That's correct. If I were to suggest that we take our Prime Minister Justin Trudeau Could you take a picture of him and do the same thing with him?

[דובר 2] (4:31 - 5:12)
Absolutely, and the scary part of that is we can just go to Google Images Download one of the pictures and then just insert it inside this app so Wow It instantly just built his face right and we're basically Compositing this face onto his face this so totally Jew is becoming Justin Trudeau instantly and Everything is happening in real time life. So Now imagine we could basically stream this video To someone and have a chat conversation where someone could believe that it is Justin.

[דובר 1] (5:12 - 5:51)
Absolutely That is unbelievable How do you feel being a Canada's Prime Minister? You all right with that? Unlike some other countries where it's not really like perhaps Kim Jong-un Wow, but this then Obviously leaves me to wonder about the you know, sort of the dark Applications that you could use this for right?

I mean have you considered the possibilities of how somebody could take these images and use them in a completely unethical way?

[דובר 2] (5:52 - 6:13)
absolutely people also general generally believe in videos as a form of Well, I saw it in a video. So it must be true I mean this even with the naked eye you can still tell that There is something unnatural about the face there are some slights artifacts, but you can imagine that in a couple of months We're gonna perfect the system and it's going to be a perfect image

[דובר 1] (6:13 - 6:36)
you believe we're very close to getting to the point where it'll be virtually impossible to tell the difference between a real image and a Manipulated digitally manipulated image.

I think so So all you need is a simple picture then using this AI technology You can control the image any way you want. Only one of me is real. Can you tell the difference?

[דובר 9] (6:37 - 6:40)
Dear people of Belgium, okay

[דובר 1] (6:40 - 6:52)
This video is really low quality, but it appears to show President Trump saying Belgium should withdraw from the Paris Climate Agreement This manipulated video was released by a political party in Belgium

[דובר 9] (6:53 - 6:58)
We all know that climate change is fake Just like this video

[דובר 1] (6:58 - 7:39)
But even low-tech fakes can have real-life consequences Like this video of what looks like a child being kidnapped It went viral in India an elaborate online hoax that created a firestorm of fear of roving child Kidnapping gangs as rumors spread two dozen people would be killed by vigilante mobs the victims suspected to be child abductors The doctored footage was lifted from this safety video in Pakistan warning people of the dangers of child abduction someone had cut it without this ending showing the child being returned a BBC report said it took a sweeping campaign to convince people the video was a fake.

[דובר 6] (7:40 - 7:42)
Do you believe that video is real?

[דובר 4] (7:45 - 8:13)
Police had to hit the streets telling people to stop sharing the video But the damage had already been done This is not hypothetical anymore So we know that this type of content whether it's fake video fake images or fake news has led to conflict in Myanmar it's led to conflict and deaths in Sri Lanka. It has led to conflicts around the world and in India There have been horrible deaths. So this is not hypothetical anymore.

[דובר 1] (8:13 - 8:28)
We are seeing real Lives put at stake because of the fake news phenomenon Fareed says fake news combines the persuasion of digital tech with the power of social media It's like nitro meets glycerin.

[דובר 4] (8:29 - 8:53)
I worry what happens to a world when literally almost anybody can create Very compelling fake content. I think that is going to lead to an information apocalypse The nightmare situation is a video of Trump saying I've launched nuclear weapons against North Korea and before anybody figures out that it's fake We're off to the races of the global nuclear meltdown. And while I don't think that is likely I also don't think it's out of the question

[דובר 1] (8:53 - 10:23)
I mean certainly that technology exists today and that has the US Defense Department on alert coming up We're heading to Washington to see the tools being developed to try to spot the fakes We remember where we were remember how we were moved by the power of these images They helped reshape politics and public opinion how we see each other and how we see the world Now imagine if someone told you they weren't worth it Real That's more likely to happen now than ever before Which is why the US Defense Department sees fake news as a clear and present danger A specialized team is investing tens of millions of dollars to develop technology to spot fakes and we're getting a sneak peek So the building's just up here and they've got some pretty strict policies about security Which means no cameras until we get inside the building So this is about as far as I can take you for now Once inside we meet Matt Turek from the Defense Advanced Research Projects Agency or the DARPA for short He's taking aim at the enemy.

[דובר 3] (10:23 - 10:51)
Who are your adversaries? Well, it could be anyone actually at this point could be an individual. It could be little resource groups It could be you know more organized groups and nation states certainly But I will point out that nation states have always had the capability to manipulate media But if technology can fuel the fakes, can it also be used to help root them out?

Turek starts simple.

[דובר 1] (10:51 - 10:58)
This plane wasn't in the original photo This detection technology can read the differences in picture resolution.

[דובר 3] (10:59 - 11:20)
It's like fingerprints that don't match There's sort of an outline of the airplane That you can see in this noise pattern and so the computer can automatically pick up on that likely the airplane Pixels come from a different camera than the than the rest of the scene How's this for video manipulation?

[דובר 1] (11:20 - 11:26)
This looks convincingly like two people sitting beside each other, but they never were

[דובר 3] (11:26 - 11:56)
So the one on the left this one here was taken earlier in the day This video was taken later and you can actually see the sunlight Reflecting off the back wall there and then they were merged together to create this video Detection technology looks for inconsistencies So here's another example of a video that's been manipulated this one is Really meant to mimic a surveillance video.

[דובר 1] (11:56 - 12:09)
We typically believe surveillance camera footage doesn't lie It's a powerful tool for police But watch again the passing car suddenly disappears, but the detectors spot the missing links in the video chain

[דובר 3] (12:10 - 12:30)
You can see this green line This is the signal and it's going to detect this frame's going to turn red at the places where the video was spliced And so basically a series of frames was removed and that produces Inconsistency in the motion signal and that's what the automated algorithm can pick up on in this case

[דובר 1] (12:31 - 12:40)
And remember when we were in la and saw how a simple photo could be turned into video Well darpa is working on spotting fakes like those two

[דובר 3] (12:41 - 13:01)
Here in particular you can see it really lighting up red because it needs to deform you know this face To be the open face and so the mouth and and some of the nose Region is all being modified. Right?

So that's the critical area of manipulation right in there. That's the hot spot, right?

[דובר 1] (13:01 - 13:21)
Exactly But turic concedes as soon as technology is developed to spot fakes Then someone creates better fakes It strikes me that you've got the sense here We've got to be able to detect and we've got to be able to stay ahead of this emerging technology or else What's the or else component of that?

[דובר 3] (13:21 - 13:50)
I think we as a society right now have significant trust in image or video if we see it Then we have faith that it happened and so the ability for An individual or a small group of people to make compelling manipulations really undermines trust You're trying to be able to spot the the fakes of the regulators out there But i'm wondering who's got the upper hand right now in some sense It's easier to generate a manipulation now than it is to detect it

[דובר 1] (13:50 - 13:59)
The u.s. Defense department may be diplomatic about the threat of fake news in trump's america But digital forensic sleuth honey farid is not

[דובר 4] (14:00 - 14:31)
There's absolutely no question that this is an arms race and the way this game ends by the way Is the adversary will always win you will always be able to create a compelling fake image or video But the ability to do that if we are successful on the forensic side Is going to take more time more effort more skill and more risk and we are going to eventually take it out of the hands Of the average person and put it into the hands of a relatively small number of people That's still a risk, but it's a significantly less risk than we have today

[דובר 1] (14:38 - 15:37)
And the risks are all around us Here's an up-to-the-minute example of how deception can influence the political perception of the migrant caravan and it didn't take sophisticated technology Images like this one went viral on right-wing facebook groups and retweeted on twitter claiming quote Mexican police are being brutalized by members of this caravan This photo was actually taken six years ago at a student protest The truth is sometimes we see what we want to see to confirm our beliefs And fake photos are used as a weapon in this war on truth This photo of an nfl player helped stoke sentiment against players who refused to stand during the us national anthem It of course was a fake This is the original photo, but the fake photo was widely shared before and after it was debunked But in this emerging technology fake images are but one weapon

[דובר 6] (15:38 - 15:41)
19 degrees. Here's what's making news right now.

[דובר 8] (15:41 - 15:53)
Imagine now the potential impact of fake audio U.S president donald trump urging east coast residents south korea's findings I have told them that their talk of appeasement with north korea will not work.

[דובר 1] (15:53 - 17:11)
They only understand one thing This is a real tweet from president trump, but that wasn't his real voice I'm heading to montreal to meet the team who created it Hello, nice to meet you and welcome to network. Thank you Jose sotelo is one of the co-founders of liar bird They claim with a few samples of recorded audio of any voice their ai technology can create a synthesized vocabulary even a synthesized conversation Hey now have you heard about this new technology, are you speaking about this new algorithm to copy voices? Hey guys, I think that they use deep learning and artificial neural networks Sure, it's still developing but the potential is clear you write the words the digital voice will repeat them Liar birds intentions are good.

The company works with the als association to help people with the disease Remember the ice bucket challenge? When als robbed the voice of one of its founders liar bird helped give it back Time to say goodbye to this computerized voice.

[דובר 10] (17:12 - 17:21)
It's a strange feeling saying your first words a second time Guess who's back bitches

[דובר 1] (17:26 - 17:32)
But sotelo concedes technology like his could help fake news fool even more people

[דובר 5] (17:32 - 18:08)
We have thought about the ethics and like the ethical implications of this technology Since the first day that we started this company actually since before that it's It's really serious like the kind of potential misuses and the consequences of these potential misuses could have on society And actually that's the thing that motivates us to speak publicly about this Is that uh By showing this to the public by letting letting them know about this we prevent the worst part of this, uh Of these potential consequences of this part of like all the evil things that could be done with this technology

[דובר 1] (18:08 - 18:19)
I wonder though if you take your audio technology and then you combine that now with some of the visual technology that's out there That would be a very powerful although inauthentic

[דובר 5] (18:19 - 18:40)
Um recreation of an image with their voice definitely and so actually we have done this in the past Last year just as a proof of concept. We did something like this.

We did a video of Obama speaking and we modified the video we modified the facial expressions and we tried to make it realistic Can you show it to me?

[דובר 7] (18:40 - 18:53)
Yeah, of course Hi everybody This night i'm happy to share with you a small announcement about a cool startup called live They launched today their website where you can create a digital copy of your voice.

[דובר 1] (18:53 - 19:29)
They only need you to record one minute of audio Where will it all end in a post-truth world as some call it? How can anyone tell what's real anymore? Remember donald trump's lewd comments caught on tape by access hollywood and when you're a star they let you do it You can do anything whatever you want grab them by the I can do anything Well trump initially apologized anyone who knows me knows these words don't reflect who I am I said it I was wrong and I apologized But later he reportedly told people in his inner circle.

[דובר 4] (19:29 - 20:03)
That wasn't his voice on the tape When for example a politician says something inappropriate they now have plausible deniability. They can say the fake video the video is fake And that's worrisome because suddenly nothing can be real anymore and already we have a lot of questioning of the media And authenticity and we have a fake news phenomenon that we've been dealing with for for two years And now it's going to be that You know plus a lot more because now it's not just you can't believe what you read But it's what you you can't believe what you see and hear and that's troubling to me

[דובר 1] (20:04 - 20:13)
Liar bird is trying to fight the fakes while its program is available to anyone online You can only use it to record your own voice

[דובר 5] (20:14 - 20:29)
Right now we don't allow people to copy the voice of anyone else and the way that we prevent that is by Requiring people to say a specific set of sentences So you cannot go into our website and put whatever audio file that you find online

[דובר 1] (20:29 - 20:43)
And create an artificial voice based on that well, I couldn't take then a recorded speech by say prime minister trudeau And and use your technology to be able to distort his message with his voice and his words exactly

[דובר 4] (20:43 - 21:02)
I'm optimistic. I think we will eventually get a handle on this But I think the coming years are going to be very dicey for us because we're not there yet We as consumers have to get smarter. We have to stop being so gullible.

We have to get out of our echo chambers We have to be more rational about how we digest and consume digital content online

[דובר 1] (21:03 - 21:18)
Back in the offices of pin screen in la how li hopes that exposing the reality of fakes will make all of us More skeptical of what we read see and hear After all the truth is still out there

[דובר 2] (21:18 - 21:40)
one of the Things that are very obvious is that you can actually use this for malicious uh purposes, right and um, the important thing here is really to show I mean, there are two options one is we don't work toward that but then you end up in the The risk that someone else would actually do right?

Well, the genie is clearly out of the bottle right now That's right.

[דובר 1] (21:40 - 21:57)
If you're working on it, there may be someone somewhere else working There there are many other experts that are also working on, you know related fields But when you look at the possible misuse of images and technology like this That just makes me wonder are you Part of the solution or are you part of the problem?

[דובר 2] (21:58 - 22:38)
I think um Obviously, um if you create, you know some type of emerging technologies It's like 3d printers where people would think about like well, I can print guns But it also has a lot of very important applications for the economy itself, right? And in our case I think it is. Um I mean, it is always unfortunate that there's always you know some certain group of people who would use would potentially use that for a different scenario, but it is Important to speak about it so that we can also address this problem in a different way I wonder what our prime minister thinks of all this good or bad.

[דובר 1] (22:39 - 22:45)
Let's ask him What do you think prime minister trudeau thumbs up or thumbs down thumbs up? Okay, we got our answer
[דובר 1] (0:06 - 0:09)
Under-18s are the biggest audience on YouTube.

[דובר 4] (0:09 - 0:15)
My favourite YouTuber is a gamer called DanTDM. I like, like, animal videos. Mr Beast.

[דובר 1] (0:16 - 0:30)
And parents and schools now rely on it as a tool to access great science content. But there's a new type of content creator using artificial intelligence to create videos full of false information.

[דובר 11] (0:30 - 0:35)
That never existed. This never happened to him. This woman doesn't exist.

Those conversations didn't happen.

[דובר 1] (0:35 - 0:46)
Our research shows that these creators take advantage of kids' clicks to cash in while spreading misinformation to classrooms around the world. And the kids seem to be buying it.

[דובר 10] (0:47 - 0:50)
I find it really interesting that humans can make electricity.

[דובר 1] (0:53 - 1:00)
Bad science videos are flooding YouTube, optimised for the algorithm with catchy titles and controversial topics.

[דובר 2] (1:00 - 1:03)
Imagine being told that the world you live in is not real.

[דובר 1] (1:05 - 1:08)
Full of pseudoscience and false information.

[דובר 8] (1:08 - 1:16)
Unpredictable patterns of highs and lows that might not be directly correlated with the effects of human activities and greenhouse gas emissions.

[דובר 1] (1:16 - 1:24)
Creators are tagging these videos as educational content. And they're often beating legitimate science videos in the race to be recommended.

[דובר 5] (1:24 - 1:41)
These videos do well because they are potentially in some way maybe conspiratorial. We're all fascinated by things that run counter to what we're officially told. And children obviously maybe are more susceptible perhaps to this than adults.

[דובר 1] (1:42 - 2:21)
We wanted to see if these videos were reaching children. So we created an experiment. We set up four children's accounts on YouTube.

Each account watched 50 science videos from legitimate creators. After only four days, one of the bad science channels cropped up in the recommended videos. Once we clicked these videos, they flooded our recommended feed.

And it's in every corner of the globe, with channels translating the videos into more than 20 languages. But would kids in the real world believe what they were seeing? We showed two examples of bad science videos to two groups of children.

One in the UK and one in Thailand.

[דובר 7] (2:21 - 2:35)
No one knows when they were built, how they were built, who built them, and most importantly, why were they built. With the right amount of pressure, the Great Pyramid could generate a tremendous amount of electricity.

[דובר 10] (2:36 - 2:40)
I find it really interesting that pyramids can make electricity.

[דובר 7] (2:40 - 2:42)
Pyramid power plants were and are possible.

[דובר 4] (2:43 - 2:47)
I was quite surprised to find out just a pile of rocks can form electricity.

[דובר 9] (2:55 - 3:02)
I thought it was really cool because I like love aliens and stuff like that.

[דובר 7] (3:02 - 3:08)
The only thing missing for the Great Pyramid of Giza to function as a power plant was a source of energy.

[דובר 9] (3:08 - 3:14)
I didn't know that people so long ago would be able to make electricity and use modern technology.

[דובר 6] (3:15 - 3:41)
Due to the recent surge in sighting reports from all over the world, the UFO community endured a period of extreme heat. The objects are said to be of exotic origin or non-human intelligence, whether alien or ancient in origin.

[דובר 1] (3:42 - 4:40)
The person who was talking sounded very professional and knew what he was talking about. We found more than 50 channels creating these bad science videos, and they are getting hundreds of thousands, sometimes millions of views. But how are they multiplying so fast?

We found out that these channels are being created using artificial intelligence. A video needs a script, and with AI, it can be generated in seconds. Then it needs a voice.

It no longer needs to be human. It's not quite there yet, but eventually we won't be able to tell the difference. Then AI can find footage from across the internet, taking from different sources, and piece together the final film.

Some footage and graphics have been stolen from legitimate educational creators and repurposed into false information. Kyle Hill, a science communication specialist, educator and YouTuber, began to notice these videos cropping up in his feed a couple of months ago.

[דובר 3] (4:40 - 5:00)
So being a YouTube creator, I always try to have my ear to the ground for what other science and technology related channels are doing. But it wasn't until one of my viewers actually pointed out that it looked like a lot of the channels they were getting recommended after watching my videos started looking very the same.

[דובר 1] (5:00 - 5:12)
And these videos do all look really similar. The logos look alike, the same subjects, and near identical thumbnails. And they're full of false information, like this.

[דובר 8] (5:12 - 5:22)
Weather patterns have seen some remarkable changes in the past decades, something which many might attribute to climate change, but these changes might not be caused by climate change at all.

[דובר 1] (5:22 - 5:54)
Once the footage is taken, the AI channels change or even ignore the original meaning. Here, they took old footage from a NASA experts video. They took out his voice and replaced it with AI narration, saying climate change isn't caused by humans, which isn't in the original.

Here, they've taken a James Webb telescope animation from a legitimate science creator. The AI video used it to say scientists are covering up that the telescope disproved the Big Bang Theory, which it never did.

[דובר 3] (5:55 - 6:07)
These channels seem to have identified the exact right thing and how to do that thing to maximize views with the least amount of actual effort.

[דובר 1] (6:07 - 6:21)
And more views equals more money through advertising revenue, with channels often getting thousands of pounds per video. With new AI tools, anyone can create channels in a matter of hours, and there's hundreds of tutorials on YouTube.

[דובר 6] (6:22 - 6:32)
So, you want to make money with AI and YouTube. I created this faceless YouTube channel using only AI to script, edit and create a faceless YouTube channel.

[דובר 1] (6:32 - 6:46)
With each video getting tens of thousands of views, these channels can mean massive payouts for creators. And creators aren't the only ones profiting. YouTube takes nearly half of advertising revenue from every video.

[דובר 5] (6:46 - 6:57)
The idea that YouTube and Google making money off the back of adverts being served against pseudoscience, AI-generated news, that seems really unethical to me.

[דובר 1] (6:57 - 7:01)
That video was actually all fake.

[דובר 4] (7:01 - 7:14)
I'm actually really confused. I thought that was 100% real. I would have probably believed it if you hadn't told us it was fake.

I think I did believe it until a few minutes ago. I'm just shocked.

[דובר 2] (7:14 - 7:38)
I think children will often take what they've seen as fact, first and foremost. And then maybe when they're a little older, start to question it. But it's not your starting point.

If you're watching something educational, you're watching it so that you learn. And we don't question, do we? It's just not in our wiring to do that.

So that's why it's such a concern.

[דובר 1] (8:01 - 8:42)
YouTube told us that they recommend YouTube Kids for under-13s, which has a higher bar for videos shown. They said they're committed to removing misinformation from their platforms. They also directed us to information panels that show additional context on conspiracy-related content.

We found this was only present for a few of the videos across the 50 channels. They didn't comment on advertising revenue they may receive from these videos. We reached out to some of the channels for comment.

One responded, saying their videos were intended for entertainment purposes and that they didn't target children. They also said the majority of their scripts were not written using AI.

[דובר 3] (8:43 - 8:55)
Good information is probably going to be pushed out. We will have so much AI-generated content that you will not want to spend the time or the effort ever sifting through it.

[דובר 2] (8:55 - 9:07)
I think this is an emerging threat. I think that we don't have a really clear understanding yet of how AI and AI-generated content is really impacting children's understanding.

[דובר 1] (9:07 - 9:13)
But some of the kids were able to spot that there was something not quite right about the videos.

[דובר 4] (9:13 - 9:28)
Maybe because of the voice, the choice of voice they had. They used an AI voice. It was fake because you could tell that it was not edited properly.

[דובר 2] (9:28 - 9:37)
As teachers, we need to have conversations with our children about what they're watching and the media that they're absorbing so that we understand that.

[דובר 1] (9:37 - 9:45)
AI is evolving fast. As these videos continue to multiply, bad science could drown out good content.